{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8207122a",
   "metadata": {},
   "source": [
    "# GPT-2 Model with OPENAI model's weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865f44de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(42)\n",
    "import model_wrapper,models\n",
    "\n",
    "import tiktoken\n",
    "from transformers import GPT2LMHeadModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e16e88",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e81c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG = {\n",
    "    \"num_epochs\":10,\n",
    "    \"batch_size\":4,\n",
    "    \"vocab_size\": 50257,    \n",
    "    \"context_len\": 1024,  \n",
    "    \"emb_dim\": 768,          \n",
    "    \"n_heads\": 8,        \n",
    "    \"n_layers\": 12,        \n",
    "    \"drop_rate\": 0.1,     \n",
    "    \"qkv_bias\": True  #GPT2 为True\n",
    "}\n",
    "\n",
    "LR= 1e-3\n",
    "WEIGHT_DECAY =0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217e2af6",
   "metadata": {},
   "source": [
    "### Set device to (type='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb94447",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6432a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载Hugging Face的官方GPT-2模型（包含OpenAI权重）\n",
    "# https://huggingface.co/openai-community/gpt2\n",
    "\n",
    "official_state_dict = GPT2LMHeadModel.from_pretrained(\"gpt2\") .state_dict()\n",
    "for name, param in official_state_dict.items():\n",
    "            print(f\"{name}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e8ead4",
   "metadata": {},
   "source": [
    "## Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6387c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_openai_weights(model,GPT_CONFIG,official_state_dict):\n",
    "    custom_state_dict = model.state_dict()\n",
    "    \n",
    "    # 1. 映射嵌入层权重\n",
    "    custom_state_dict[\"tok_emb.weight\"] =  official_state_dict[\"transformer.wte.weight\"].clone()\n",
    "    custom_state_dict[\"pos_emb.weight\"] = official_state_dict[\"transformer.wpe.weight\"].clone()\n",
    "    \n",
    "    # 2. 映射Transformer层权重（每个block的参数）\n",
    "    for i in range(GPT_CONFIG['n_layers']):\n",
    "        # layer norm 1\n",
    "        custom_state_dict[f\"trf_blocks.{i}.norm1.scale\"] = official_state_dict[f\"transformer.h.{i}.ln_1.weight\"].clone()\n",
    "        custom_state_dict[f\"trf_blocks.{i}.norm1.shift\"] = official_state_dict[f\"transformer.h.{i}.ln_1.bias\"].clone()\n",
    "        \n",
    "        #attention \n",
    "        #拆分c_attn为W_q、W_k、W_v（c_attn.weight形状：[768, 2304] = [768, 768*3]）\n",
    "        c_attn_weight = official_state_dict[f\"transformer.h.{i}.attn.c_attn.weight\"] #[768, 2304]\n",
    "        w_q_weight, w_k_weight, w_v_weight = torch.split(c_attn_weight, 768, dim=1)\n",
    "        custom_state_dict[f\"trf_blocks.{i}.att.W_q.weight\"] = w_q_weight.clone()\n",
    "        custom_state_dict[f\"trf_blocks.{i}.att.W_k.weight\"] = w_k_weight.clone()\n",
    "        custom_state_dict[f\"trf_blocks.{i}.att.W_v.weight\"] = w_v_weight.clone()\n",
    "        c_attn_bias = official_state_dict[f\"transformer.h.{i}.attn.c_attn.bias\"] #[2304]\n",
    "        w_q_bias, w_k_bias, w_v_bias = torch.split(c_attn_bias, 768, dim=0) \n",
    "        custom_state_dict[f\"trf_blocks.{i}.att.W_q.bias\"] = w_q_bias.clone()\n",
    "        custom_state_dict[f\"trf_blocks.{i}.att.W_k.bias\"] = w_k_bias.clone()\n",
    "        custom_state_dict[f\"trf_blocks.{i}.att.W_v.bias\"] = w_v_bias.clone()\n",
    "        # out_proj  融合多头\n",
    "        custom_state_dict[f\"trf_blocks.{i}.att.out_proj.weight\"] = official_state_dict[f\"transformer.h.{i}.attn.c_proj.weight\"].clone()\n",
    "        custom_state_dict[f\"trf_blocks.{i}.att.out_proj.bias\"] = official_state_dict[f\"transformer.h.{i}.attn.c_proj.bias\"].clone()\n",
    "        \n",
    "        # layer norm 2\n",
    "        custom_state_dict[f\"trf_blocks.{i}.norm2.scale\"] = official_state_dict[f\"transformer.h.{i}.ln_2.weight\"].clone()\n",
    "        custom_state_dict[f\"trf_blocks.{i}.norm2.shift\"] = official_state_dict[f\"transformer.h.{i}.ln_2.bias\"].clone()\n",
    "        \n",
    "        \n",
    "        # FFN \n",
    "        custom_state_dict[f\"trf_blocks.{i}.ff.layers.0.weight\"] = official_state_dict[f\"transformer.h.{i}.mlp.c_fc.weight\"].T.clone()  #转置目的是解决不同框架（TensorFlow → PyTorch）间线性层权重维度的定义差异\n",
    "        custom_state_dict[f\"trf_blocks.{i}.ff.layers.0.bias\"] = official_state_dict[f\"transformer.h.{i}.mlp.c_fc.bias\"].clone()\n",
    "\n",
    "        custom_state_dict[f\"trf_blocks.{i}.ff.layers.3.weight\"] = official_state_dict[f\"transformer.h.{i}.mlp.c_proj.weight\"].T.clone() #同理\n",
    "        custom_state_dict[f\"trf_blocks.{i}.ff.layers.3.bias\"] = official_state_dict[f\"transformer.h.{i}.mlp.c_proj.bias\"].clone()\n",
    "\n",
    "    \n",
    "    # 3. 映射最终层归一化和输出层\n",
    "    custom_state_dict[\"final_norm.scale\"] = official_state_dict[\"transformer.ln_f.weight\"].clone()\n",
    "    custom_state_dict[\"final_norm.shift\"] = official_state_dict[\"transformer.ln_f.bias\"].clone()\n",
    "    \n",
    "    # (out_head)与tok_emb共享权重，无需额外映射 (对应gpt2的lm_head.weight: torch.Size([50257, 768]))\n",
    "    \n",
    "    \n",
    "    # for name, param in custom_state_dict.items():\n",
    "    #        print(f\"{name}: {param.shape}\")\n",
    "    \n",
    "    model.load_state_dict(custom_state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844d197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.GPTModel(GPT_CONFIG)\n",
    "load_openai_weights(model,GPT_CONFIG,official_state_dict)\n",
    "model.to(device)\n",
    "model.eval() \n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "start_context = \"I turned to Mrs\"\n",
    "for _ in range(5):\n",
    "    model_wrapper.generate_and_print(model,tokenizer,device,start_context,100,0.8,50,0.95,50256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829ed6a9",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b0aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath ='../model/gpt2_weight.pt'\n",
    "model_wrapper.savemodel(modelpath,model,None,GPT_CONFIG)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
