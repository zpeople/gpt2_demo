{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8207122a",
   "metadata": {},
   "source": [
    "# GPT-2 Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "865f44de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.testing import assert_close\n",
    "torch.manual_seed(42)\n",
    "import tool, loaddata ,model_wrapper\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e16e88",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e81c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_SKIP_TEST =True\n",
    "IS_EN =True\n",
    "IS_TRAIN=True\n",
    "\n",
    "\n",
    "GPT_CONFIG = {\n",
    "    \"num_epochs\":10,\n",
    "    \"batch_size\":4,\n",
    "    \"vocab_size\": 50257,     # 词汇表大小\n",
    "    \"context_len\": 256,  # 上下文长度\n",
    "    \"emb_dim\": 768,          # 嵌入维度\n",
    "    \"n_heads\": 8,           # 注意力头的数量\n",
    "    \"n_layers\": 12,          # 层数\n",
    "    \"drop_rate\": 0.1,        # dropout率\n",
    "    \"qkv_bias\": False ,      # 查询-键-值偏置\n",
    "}\n",
    "\n",
    "TOKEN_TYPE=\"gpt2\"\n",
    "# TOKEN_TYPE=\"cl100k_base\"\n",
    "LR= 1e-3\n",
    "WEIGHT_DECAY =0.1\n",
    "\n",
    "EVAL_FREQ = 5\n",
    "EVAL_ITER = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d784ca60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug 13 18:20:29 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.94                 Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 960       WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| 30%   47C    P8             18W /  180W |    2796MiB /   4096MiB |     16%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      3504    C+G   ...n\\138.0.3351.121\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A      4316    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A      5616    C+G   ...1915\\office6\\promecefpluginhost.exe      N/A      |\n",
      "|    0   N/A  N/A      9204    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A      9852    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     10112    C+G   ...l\\Doubao\\Application\\app\\Doubao.exe      N/A      |\n",
      "|    0   N/A  N/A     11832    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A     12572    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     13212    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     13732    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     13904    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     14356    C+G   ...m Files\\TencentDocs\\TencentDocs.exe      N/A      |\n",
      "|    0   N/A  N/A     15196      C   ...\\SEELE\\.conda\\envs\\DL_py\\python.exe      N/A      |\n",
      "|    0   N/A  N/A     15208    C+G   ...64__8wekyb3d8bbwe\\CalculatorApp.exe      N/A      |\n",
      "|    0   N/A  N/A     15436    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A     16948    C+G   ...tease\\GameViewer\\bin\\GameViewer.exe      N/A      |\n",
      "|    0   N/A  N/A     18808    C+G   ...n\\138.0.3351.121\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     19112    C+G   ...2.0_x64__w1wdnht996qgy\\LinkedIn.exe      N/A      |\n",
      "|    0   N/A  N/A     19680    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     20020    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     20992    C+G   E:\\Microsoft VS Code\\Code.exe               N/A      |\n",
      "|    0   N/A  N/A     21960    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     22392      C   ...\\SEELE\\.conda\\envs\\DL_py\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217e2af6",
   "metadata": {},
   "source": [
    "### Set device to (type='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cb94447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8f4f13",
   "metadata": {},
   "source": [
    "### Tensorboard Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "434f8031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start experiment: 2025-08-13_18-20-30\n"
     ]
    }
   ],
   "source": [
    "# 创建一个日志写入器\n",
    "import time\n",
    "starttime = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "print(\"Start experiment:\", starttime)\n",
    "logpath =\"../log/\"\n",
    "log_writer = SummaryWriter(log_dir=logpath+starttime[:16],comment=starttime[:16],flush_secs=60)#以实验时间命名\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e411c4",
   "metadata": {},
   "source": [
    "## Define GPT-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f689863",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg['vocab_size'],cfg['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(cfg['context_len'],cfg['emb_dim'])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks =  nn.Sequential(\n",
    "            *[model_wrapper.TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = model_wrapper.LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg['emb_dim'],cfg['vocab_size'],bias=False\n",
    "        )\n",
    "       \n",
    "    def forward(self,in_idx):\n",
    "        batch_size, seq_len = in_idx.shape  \n",
    "        tok_embeds = self.tok_emb(in_idx) \n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len,device=in_idx.device))  \n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f268a8f",
   "metadata": {},
   "source": [
    "### View structure of model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3934cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "函数 test_GPT2_model 已跳过执行\n"
     ]
    }
   ],
   "source": [
    "#GPT2 小型（Small）：12 层 Transformer 解码器，隐藏层维度 768，注意力头数 12，总参数约 1.2 亿\n",
    "@tool.skip_execution(skip=IS_SKIP_TEST)\n",
    "def test_GPT2_model():\n",
    "    CONFIG = {\n",
    "    \"num_epochs\":1,\n",
    "    \"batch_size\":1,\n",
    "    \"vocab_size\": 50257,     \n",
    "    \"context_len\": 512,  \n",
    "    \"emb_dim\": 768,          \n",
    "    \"n_heads\": 8,          \n",
    "    \"n_layers\": 12,          \n",
    "    \"drop_rate\": 0.1,       \n",
    "    \"qkv_bias\": False ,      \n",
    "    }   \n",
    "    model = GPTModel(CONFIG)\n",
    "    model.to(device)\n",
    "\n",
    "    # attention_new 参数减少量 = (304,556,544 - 163,008,000)\n",
    "    total_params =sum(p.numel() for p in model.parameters())\n",
    "\n",
    "    print(f\"Total number of parameters: {total_params:,}\") #163,008,000\n",
    "\n",
    "    #权重共享， W_emb和W_out指向同一块内存，模型训练时只会更新这一个矩阵，避免了维护两个独立矩阵的开销\n",
    "    total_params_gpt2 = total_params - sum(p.numel()for p in model.out_head.parameters())\n",
    "   \n",
    "    print(f\"Number of trainable parameters \"\n",
    "        f\"considering weight tying: {total_params_gpt2:,}\") #124,017,408\n",
    "    return model\n",
    "    \n",
    "test_GPT2_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0978e686",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1ba29a",
   "metadata": {},
   "source": [
    "### Select which language of the text to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d85e6821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total char: 20479\n",
      "train char: 16383\n",
      "valid char: 4096 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if IS_EN :\n",
    "    file_path =\"../datasets/the-verdict.txt\"\n",
    "    train_data, valid_data =loaddata.load_data_en(file_path)\n",
    "else:\n",
    "    train_data, valid_data = loaddata.load_data_cn(True,0.8)\n",
    "    \n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15db966b",
   "metadata": {},
   "source": [
    "## GPTDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4745946",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool.train_execution(IS_TRAIN)\n",
    "def Dataloadering():\n",
    "    train_loader = model_wrapper.GPTDataloader(\n",
    "        train_data,\n",
    "        TOKEN_TYPE,\n",
    "        batch_size = GPT_CONFIG['batch_size'],\n",
    "        max_len = GPT_CONFIG[\"context_len\"],\n",
    "        stride = GPT_CONFIG[\"context_len\"] // 2, #适度重叠（stride = max_len // 2）\n",
    "        drop_last=True,\n",
    "        shuffle= True, #训练时打乱，验证 / 测试时不打乱：训练时打乱是为了提升泛化能力\n",
    "        num_works=0   \n",
    "        )\n",
    "\n",
    "    print(F'共{len(train_loader)}个批次，'\n",
    "        f'每批{train_loader.batch_size}个样本，'\n",
    "        f'每个样本是长度为 {train_loader.dataset.max_len} 的 token 序列')\n",
    "\n",
    "\n",
    "    print(\"Train loader:\")\n",
    "    if len(train_loader)<10: #测试的时候查看一下数据，数据过大，耗时很长\n",
    "        x, y =next(iter(train_loader))\n",
    "        print(x.shape, y.shape)\n",
    "\n",
    "\n",
    "    valid_loader = model_wrapper.GPTDataloader(\n",
    "        valid_data,\n",
    "        TOKEN_TYPE,\n",
    "        batch_size = GPT_CONFIG['batch_size'],\n",
    "        max_len = GPT_CONFIG[\"context_len\"],\n",
    "        stride = GPT_CONFIG[\"context_len\"] ,\n",
    "        drop_last=False, # 验证 / 测试阶段：需要完整评估所有样本的性能，不能遗漏任何数据点\n",
    "        shuffle= False, #验证 / 测试时不打乱是为了结果可复现，方便对比不同模型的性能\n",
    "        num_works=0\n",
    "        )\n",
    "\n",
    "    print(\"Validation loader:\")\n",
    "    if len(valid_loader)<10:\n",
    "        x, y =next(iter(valid_loader))\n",
    "        print(x.shape, y.shape)\n",
    "        \n",
    "    return train_loader,valid_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e8ead4",
   "metadata": {},
   "source": [
    "## Training model\n",
    "### Training process function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c831d6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model_process(model,train_loader,valid_loader,\n",
    "                        optimizer,device,num_epochs,\n",
    "                        eval_freq,eval_iter,\n",
    "                        start_context,tokenizer):\n",
    "    train_losses,val_losses= [],[]\n",
    "    track_tokens_seen =[]\n",
    "    tokens_seen,global_step = 0, -1\n",
    "    for epoch in  tqdm(range(num_epochs), desc=\"training\"):\n",
    "        model.train() #开启训练 启用dropout、启用Batchnorm\n",
    "        for input_batch,target_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\", leave=False):\n",
    "            optimizer.zero_grad()\n",
    "            loss = model_wrapper.calc_loss_batch(input_batch,target_batch,model,device) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step +=1\n",
    "            \n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = model_wrapper.evaluate_model(model,train_loader,valid_loader,device,eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                log_writer.add_scalar('Training/Train_Loss', train_loss, global_step)\n",
    "                log_writer.add_scalar('Training/Val_Loss', val_loss, global_step)\n",
    "                print(f'EP: {epoch+1} STEP: {global_step} '\n",
    "                    f'{f\"T_LOSS: {train_loss:.3f}\" if train_loss is not None else \"T_LOSS: None \"} '\n",
    "                    f'{f\"V_LOSS: {val_loss:.3f}\" if val_loss is not None else \"V_LOSS: None\"}'\n",
    "                    )\n",
    "                model_wrapper.generate_and_print(model,tokenizer,device,start_context,20)\n",
    "    return train_losses,val_losses,track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b33a1b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! tensorboard --logdir=../log  --port=6006 --host=0.0.0.0  \n",
    "# ssh -L 8888:localhost:6006 zzz@172.23.207.112    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "755ce8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process text: 100%|██████████| 1/1 [00:00<00:00, 142.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 31\n",
      "共7个批次，每批4个样本，每个样本是长度为 256 的 token 序列\n",
      "Train loader:\n",
      "torch.Size([4, 256]) torch.Size([4, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process text: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 4\n",
      "Validation loader:\n",
      "torch.Size([4, 256]) torch.Size([4, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP: 1 STEP: 0 T_LOSS: 9.528 V_LOSS: 9.845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I turned to Mrs,,,,,,,,,,,,,,,,,,,,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP: 1 STEP: 5 T_LOSS: 6.593 V_LOSS: 7.131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I turned to Mrs                    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:  10%|█         | 1/10 [00:58<08:48, 58.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP: 2 STEP: 10 T_LOSS: 5.860 V_LOSS: 7.168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I turned to Mrs.                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:  20%|██        | 2/10 [01:52<07:28, 56.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP: 3 STEP: 15 T_LOSS: 5.914 V_LOSS: 7.279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I turned to Mrs the, the, the, the, the, the, the, the, the, the the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP: 3 STEP: 20 T_LOSS: 5.782 V_LOSS: 7.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:  30%|███       | 3/10 [02:53<06:46, 58.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I turned to Mrs.                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP: 4 STEP: 25 T_LOSS: 5.665 V_LOSS: 7.482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I turned to Mrs.                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:  40%|████      | 4/10 [03:48<05:40, 56.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP: 5 STEP: 30 T_LOSS: 5.444 V_LOSS: 7.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I turned to Mrs.                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:  50%|█████     | 5/10 [04:41<04:36, 55.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP: 6 STEP: 35 T_LOSS: 5.534 V_LOSS: 7.535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I turned to Mrs.                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP: 6 STEP: 40 T_LOSS: 5.244 V_LOSS: 7.311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I turned to Mrs.  \".               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:  60%|██████    | 6/10 [05:39<03:45, 56.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP: 7 STEP: 45 T_LOSS: 5.233 V_LOSS: 7.372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I turned to Mrs. \" to the picture a of the picture a- the picture of the picture to the picture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:  70%|███████   | 7/10 [06:34<02:47, 55.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP: 8 STEP: 50 T_LOSS: 4.812 V_LOSS: 7.358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I turned to Mrs.  \".               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP: 8 STEP: 55 T_LOSS: 4.201 V_LOSS: 7.031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:  80%|████████  | 8/10 [07:34<01:54, 57.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I turned to Mrs.  \".               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP: 9 STEP: 60 T_LOSS: 3.508 V_LOSS: 6.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I turned to Mrs.                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:  90%|█████████ | 9/10 [08:29<00:56, 56.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP: 10 STEP: 65 T_LOSS: 3.000 V_LOSS: 6.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I turned to Mrs.                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 10/10 [09:23<00:00, 56.36s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([9.527825546264648,\n",
       "  6.592583560943604,\n",
       "  5.8596649169921875,\n",
       "  5.9144796371459964,\n",
       "  5.782247638702392,\n",
       "  5.6645583152771,\n",
       "  5.443800163269043,\n",
       "  5.533572578430176,\n",
       "  5.244353771209717,\n",
       "  5.233304786682129,\n",
       "  4.812401390075683,\n",
       "  4.201342678070068,\n",
       "  3.5084914684295656,\n",
       "  3.0002678871154784],\n",
       " [9.844965934753418,\n",
       "  7.13070821762085,\n",
       "  7.168105602264404,\n",
       "  7.279229640960693,\n",
       "  7.4770307540893555,\n",
       "  7.48203182220459,\n",
       "  7.475358963012695,\n",
       "  7.535090923309326,\n",
       "  7.310979843139648,\n",
       "  7.371764659881592,\n",
       "  7.358284950256348,\n",
       "  7.0310258865356445,\n",
       "  6.948094844818115,\n",
       "  6.941988468170166],\n",
       " [1024,\n",
       "  6144,\n",
       "  11264,\n",
       "  16384,\n",
       "  21504,\n",
       "  26624,\n",
       "  31744,\n",
       "  36864,\n",
       "  41984,\n",
       "  47104,\n",
       "  52224,\n",
       "  57344,\n",
       "  62464,\n",
       "  67584])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelpath ='../model/model_and_optimizer.pth'\n",
    "start_context = \"I turned to Mrs\"\n",
    "tokenizer = tiktoken.get_encoding(TOKEN_TYPE)\n",
    "\n",
    "\n",
    "@tool.train_execution(IS_TRAIN)\n",
    "def training(savemodel=False):\n",
    "    model = GPTModel(GPT_CONFIG)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(),lr=LR,weight_decay=WEIGHT_DECAY)\n",
    "    train_loader,valid_loader = Dataloadering()\n",
    "    result=train_model_process(model,train_loader,valid_loader,\n",
    "                                                                optimizer,device,num_epochs=GPT_CONFIG['num_epochs'],\n",
    "                                                                eval_freq=EVAL_FREQ,eval_iter=EVAL_ITER,\n",
    "                                                                start_context=start_context,\n",
    "                                                                tokenizer=tokenizer\n",
    "                                                                )\n",
    "    if savemodel:\n",
    "        model_wrapper.savemodel(modelpath,model,optimizer)  \n",
    "        \n",
    "    return result\n",
    "\n",
    "training(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "968b45e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829ed6a9",
   "metadata": {},
   "source": [
    "## Load the parameters of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6ca038",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d20c7989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttendtion_new(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttendtion_new(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttendtion_new(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttendtion_new(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttendtion_new(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttendtion_new(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttendtion_new(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttendtion_new(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttendtion_new(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttendtion_new(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttendtion_new(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttendtion_new(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(modelpath, map_location=device)\n",
    "model = GPTModel(GPT_CONFIG)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.to(device)\n",
    "model.eval() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04242bb",
   "metadata": {},
   "source": [
    "### Test the generation capability of the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80e9e17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I turned to Mrs. And his painting.      \"How,\" she said. To the complex after to me out-rooms, and in the demandham found a hood. \"Yes, he was dead out of loing he had not,\" she said.  \"--had he liked that it. \"I said. I turned\"What.       He stood tell me--c. \"Ah had not the picture dep in a\n",
      "I turned to Mrs. Stroud! She sent for you say. \"Ah, I couldn. \"I could. Gisburn's that, passing Jack's only irre placed\"id had begun to me, my picture.  \"By of the ax't say on my companion.  \"You the only in a trace of saying.    \"Oh, the only between the fact, one might the Riv my.  \" ( of the dining't say.  \n",
      "I turned to Mrs. Mrs. I must he never, as a good he had forgotten againwas it was to put the last, my host to see it was _rose looking-c the man of the first-roomsisburn, poor. I don't say it to see it. \"Why it. \"Ah, who get to display of the dining. I had myself to see it.   \"I remember-century old the fact. It was his pictures.  \n",
      "I turned to Mrs.  \"Well, and I had always their stood I felt it happened she was not it was a feather_ he res to see the room, he had forgotten to every he was just at the reason_ here my work. \"By not to my dear Rickham--the only a little _rose I knew me to do of the sketch of the Strouds_ drawing-rooms, I felt what it happened after it. \"Ah.  \"I is at the\n",
      "I turned to Mrs.  \" only no not to have my painting.   I must when I had lit a glimpse I felt he was dead; and I asked his admire_ he had seen a wall.    But, in the Riv the first time only protest--so it were, one v I cried now it was _that.  \"Oh, you say a pale first I claimed. To the fact, on the first the ensuing of my. \"Moon-chair:\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    model_wrapper.generate_and_print(model,tokenizer,device,start_context,100,0.8,50,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ab9106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
